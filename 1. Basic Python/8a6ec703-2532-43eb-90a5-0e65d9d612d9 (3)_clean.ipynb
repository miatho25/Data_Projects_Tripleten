{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f85a80d2",
   "metadata": {},
   "source": "## Basic Python - Project <a id='intro'></a>"
  },
  {
   "cell_type": "markdown",
   "id": "a1262df4",
   "metadata": {},
   "source": "## Introduction <a id='intro'></a>\nIn this project, you will work with data from the entertainment industry. You will study a dataset with records on movies and shows. The research will focus on the \"Golden Age\" of television, which began in 1999 with the release of *The Sopranos* and is still ongoing.\n\nThe aim of this project is to investigate how the number of votes a title receives impacts its ratings. The assumption is that highly-rated shows (we will focus on TV shows, ignoring movies) released during the \"Golden Age\" of television also have the most votes.\n\n### Stages \nData on movies and shows is stored in the `/datasets/movies_and_shows.csv` file. There is no information about the quality of the data, so you will need to explore it before doing the analysis.\n\nFirst, you'll evaluate the quality of the data and see whether its issues are significant. Then, during data preprocessing, you will try to account for the most critical problems.\n \nYour project will consist of three stages:\n 1. Data overview\n 2. Data preprocessing\n 3. Data analysis"
  },
  {
   "cell_type": "raw",
   "id": "cb7ddf82",
   "metadata": {},
   "source": "You'll need `pandas`, so import it."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1727d3f8",
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": "# importing pandas\nimport pandas as pd"
  },
  {
   "cell_type": "markdown",
   "id": "9821beeb",
   "metadata": {},
   "source": "Read the `movies_and_shows.csv` file from the `datasets` folder and save it in the `df` variable:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5a1402",
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": "# reading the files and storing them to df\nmv_and_shows = '/datasets/movies_and_shows.csv'\ndf = pd.read_csv('/datasets/movies_and_shows.csv')"
  },
  {
   "cell_type": "markdown",
   "id": "1cd0a96d",
   "metadata": {},
   "source": "Print the first 10 table rows:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd92001",
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": "# obtaining the first 10 rows from the df table\n# hint: you can use head() and tail() in Jupyter Notebook without wrapping them into print()\ndf.head(10)"
  },
  {
   "cell_type": "markdown",
   "id": "e579aa91",
   "metadata": {},
   "source": "Obtain the general information about the table with one command:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf66d2a",
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": "# obtaining general information about the data in df\ndf.info()"
  },
  {
   "cell_type": "markdown",
   "id": "e91f62a7",
   "metadata": {},
   "source": "The table contains nine columns. The majority store the same data type: object. The only exceptions are `'release Year'` (int64 type), `'imdb sc0re'` (float64 type) and `'imdb v0tes'` (float64 type). Scores and votes will be used in our analysis, so it's important to verify that they are present in the dataframe in the appropriate numeric format. Three columns (`'TITLE'`, `'imdb sc0re'` and `'imdb v0tes'`) have missing values.\n\nAccording to the documentation:\n- `'name'` — actor/director's name and last name\n- `'Character'` — character played (for actors)\n- `'r0le '` — the person's contribution to the title (it can be in the capacity of either actor or director)\n- `'TITLE '` — title of the movie (show)\n- `'  Type'` — show or movie\n- `'release Year'` — year when movie (show) was released\n- `'genres'` — list of genres under which the movie (show) falls\n- `'imdb sc0re'` — score on IMDb\n- `'imdb v0tes'` — votes on IMDb\n\nWe can see three issues with the column names:\n1. Some names are uppercase, while others are lowercase.\n2. There are names containing whitespace.\n3. A few column names have digit '0' instead of letter 'o'. \n"
  },
  {
   "cell_type": "markdown",
   "id": "c5dc9111",
   "metadata": {},
   "source": "## Stage 2. Data preprocessing <a id='data_preprocessing'></a>\nCorrect the formatting in the column headers and deal with the missing values. Then, check whether there are duplicates in the data."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c850d13",
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": "# the list of column names in the df table\ncolumn_names = df.columns\ncolumn_names"
  },
  {
   "cell_type": "markdown",
   "id": "5f966df9",
   "metadata": {},
   "source": "Change the column names according to the rules of good style:\n* If the name has several words, use snake_case\n* All characters must be lowercase\n* Remove whitespace\n* Replace zero with letter 'o'"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a1dc11",
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": "# renaming columns\ndf = df.rename(columns={'   name': 'name', 'Character': 'character', 'r0le': 'role', 'TITLE': 'title', '  Type': 'type', 'release Year': 'release_year', 'genres': 'genres', 'imdb sc0re': 'imdb_score', 'imdb v0tes': 'imdb_votes'})"
  },
  {
   "cell_type": "markdown",
   "id": "464fbd04",
   "metadata": {},
   "source": "Check the result. Print the names of the columns once more:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb6527f",
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": "# checking result: the list of column names\ndf.columns"
  },
  {
   "cell_type": "markdown",
   "id": "14d9c319",
   "metadata": {},
   "source": "### Missing values <a id='missing_values'></a>\nFirst, find the number of missing values in the table. To do so, combine two `pandas` methods:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c427f2",
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": "# calculating missing values\ndf.isna().sum()"
  },
  {
   "cell_type": "markdown",
   "id": "c8272df3",
   "metadata": {},
   "source": "We identified missing values in several columns. While the missing value in `'title'` isn't critical, missing values in `'imdb_score'` and `'imdb_votes'` affect around 6% of the data, which could impact our analysis. To ensure data integrity, we'll drop all rows with missing values."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599d5550",
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": "# dropping rows where columns with scores, and votes have missing values\ndf = df.dropna()\ndf"
  },
  {
   "cell_type": "markdown",
   "id": "2156887f",
   "metadata": {},
   "source": "Make sure the table doesn't contain any more missing values. Count the missing values again."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c0b0ce",
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": "# counting missing values\ndf.isna().sum()"
  },
  {
   "cell_type": "markdown",
   "id": "a7dc7aa0",
   "metadata": {},
   "source": "### Duplicates <a id='duplicates'></a>\nFind the number of duplicate rows in the table using one command:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9227df01",
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": "# counting duplicate rows\nduplicates = df.duplicated().sum()\nduplicates"
  },
  {
   "cell_type": "markdown",
   "id": "a1ed6640",
   "metadata": {},
   "source": "There are two clear duplicates in the printed rows. We can safely remove them.\nCall the `pandas` method for getting rid of duplicate rows:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724d5bc8",
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": "# removing duplicate rows\ndf = df.drop_duplicates()"
  },
  {
   "cell_type": "markdown",
   "id": "fc8c77ba",
   "metadata": {},
   "source": "Check for duplicate rows once more to make sure you have removed all of them:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8091a9bc",
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": "# checking for duplicates\ndf"
  },
  {
   "cell_type": "markdown",
   "id": "1d802b07",
   "metadata": {},
   "source": "Now get rid of implicit duplicates in the `'type'` column. For example, the string `'SHOW'` can be written in different ways. These kinds of errors will also affect the result."
  },
  {
   "cell_type": "markdown",
   "id": "d5f987ed",
   "metadata": {},
   "source": "Print a list of unique `'type'` names, sorted in alphabetical order. To do so:\n* Retrieve the intended dataframe column \n* Apply a sorting method to it\n* For the sorted column, call the method that will return all unique column values"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7b0ac5",
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": "# viewing unique type names\ndf['type'].unique()\nunique_types = sorted(df['type'].unique())\nunique_types"
  },
  {
   "cell_type": "markdown",
   "id": "ac6e8b18",
   "metadata": {},
   "source": "Look through the list to find implicit duplicates of `'show'` (`'movie'` duplicates will be ignored since the assumption is about shows). These could be names written incorrectly or alternative names of the same genre.\n\nYou will see the following implicit duplicates:\n* `'shows'`\n* `'SHOW'`\n* `'tv show'`\n* `'tv shows'`\n* `'tv series'`\n* `'tv'`\n\nTo get rid of them, declare the function `replace_wrong_show()` with two parameters: \n* `wrong_shows_list=` — the list of duplicates\n* `correct_show=` — the string with the correct value\n\nThe function should correct the names in the `'type'` column from the `df` table (i.e., replace each value from the `wrong_shows_list` list with the value in `correct_show`)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff944f9",
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": "# function for replacing implicit duplicates\ndef replace_wrong_show(wrong_shows_list, correct_show):\n    df['type'] = df['type'].replace(wrong_shows_list, correct_show)\nwrong_shows = ['shows', 'SHOW', 'tv show', 'tv shows', 'tv series', 'tv']\n\n\n"
  },
  {
   "cell_type": "markdown",
   "id": "d02d13a6",
   "metadata": {},
   "source": "Call `replace_wrong_show()` and pass it arguments so that it clears implicit duplicates and replaces them with `SHOW`:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2217e53",
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": "# removing implicit duplicates\nreplace_wrong_show(wrong_shows, 'show')"
  },
  {
   "cell_type": "markdown",
   "id": "318b09f7",
   "metadata": {},
   "source": "Make sure the duplicate names are removed. Print the list of unique values from the `'type'` column:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d49d73",
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": "# viewing unique genre names\nunique_types = sorted(df['type'].unique())\nunique_types"
  },
  {
   "cell_type": "markdown",
   "id": "18b2049e",
   "metadata": {},
   "source": "### Conclusions <a id='data_preprocessing_conclusions'></a>\nWe detected three issues with the data:\n\n- Incorrect header styles\n- Missing values\n- Duplicate rows and implicit duplicates\n\nThe headers have been cleaned up to make processing the table simpler.\n\nAll rows with missing values have been removed. \n\nThe absence of duplicates will make the results more precise and easier to understand.\n\nNow we can move on to our analysis of the prepared data."
  },
  {
   "cell_type": "markdown",
   "id": "1aa0f1b1",
   "metadata": {},
   "source": "## Stage 3. Data analysis <a id='hypotheses'></a>"
  },
  {
   "cell_type": "markdown",
   "id": "f8fb6a0e",
   "metadata": {},
   "source": "Based on the previous project stages, you can now define how the assumption will be checked. Calculate the average amount of votes for each score (this data is available in the `imdb_score` and `imdb_votes` columns), and then check how these averages relate to each other. If the averages for shows with the highest scores are bigger than those for shows with lower scores, the assumption appears to be true.\n\nBased on this, complete the following steps:\n\n- Filter the dataframe to only include shows released in 1999 or later.\n- Group scores into buckets by rounding the values of the appropriate column (a set of 1-10 integers will help us make the outcome of our calculations more evident without damaging the quality of our research).\n- Identify outliers among scores based on their number of votes, and exclude scores with few votes.\n- Calculate the average votes for each score and check whether the assumption matches the results."
  },
  {
   "cell_type": "markdown",
   "id": "0ea2cb51",
   "metadata": {},
   "source": "To filter the dataframe and only include shows released in 1999 or later, you will take two steps. First, keep only titles published in 1999 or later in our dataframe. Then, filter the table to only contain shows (movies will be removed)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a704aa1",
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": "# using conditional indexing modify df so it has only titles released after 1999 (with 1999 included)\n# give the slice of dataframe new name\ndata_filtered = df[df['release_year'] >= 1999]\ndata_filtered"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128dc6a9",
   "metadata": {
    "scrolled": true,
    "trusted": false
   },
   "outputs": [],
   "source": "# repeat conditional indexing so df has only shows (movies are removed as result)\ndf_filtered = df[df['type'] == 'show']\ndf_filtered"
  },
  {
   "cell_type": "markdown",
   "id": "9648040c",
   "metadata": {},
   "source": "The scores that are to be grouped should be rounded. For instance, titles with scores like 7.8, 8.1, and 8.3 will all be placed in the same bucket with a score of 8."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bbd5c0",
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": "# rounding column with scores\ndf_shows_1999_plus = df.loc[(df['release_year'] >= 1999) & (df['type'] == 'show')].copy()\ndf_shows_1999_plus.loc[:, 'score_bucket'] = df_shows_1999_plus['imdb_score'].round(0).astype(int)\n#checking the outcome with tail()\ndf_shows_1999_plus[['imdb_score', 'score_bucket']].tail()"
  },
  {
   "cell_type": "markdown",
   "id": "36dbd00a",
   "metadata": {},
   "source": "It is now time to identify outliers based on the number of votes."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b55e95",
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": "# Use groupby() for scores and count all unique values in each group, print the result\nscore_counts = df_shows_1999_plus.groupby('score_bucket')['imdb_votes'].count()\nscore_counts"
  },
  {
   "cell_type": "markdown",
   "id": "1ba6daae",
   "metadata": {},
   "source": "Based on the aggregation performed, it is evident that scores 2 (24 voted shows), 3 (27 voted shows), and 10 (only 8 voted shows) are outliers. There isn't enough data for these scores for the average number of votes to be meaningful."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2017bd",
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": "df_filtered = df_shows_1999_plus[~df_shows_1999_plus['score_bucket'].isin([2, 3, 10])]\nprint(sorted(df_filtered['score_bucket'].unique()))"
  },
  {
   "cell_type": "markdown",
   "id": "bd468c46",
   "metadata": {},
   "source": "To obtain the mean numbers of votes for the selected scores (we identified a range of 4-9 as acceptable), use conditional filtering and grouping."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1867e0e",
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": "# filter dataframe using two conditions (scores to be in the range 4-9)\ndf_filtered = df_shows_1999_plus[(df_shows_1999_plus['score_bucket'] >= 4) & (df_shows_1999_plus['score_bucket'] <= 9)]\n# group scores and corresponding average number of votes, reset index and print the result\naverage_votes = df_filtered.groupby('score_bucket')['imdb_votes'].mean().reset_index()\naverage_votes"
  },
  {
   "cell_type": "markdown",
   "id": "96a66d14",
   "metadata": {},
   "source": "Now for the final step! Round the column with the averages, rename both columns, and print the dataframe in descending order."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5999051b",
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": "# round column with averages\naverage_votes['imdb_votes'] = average_votes['imdb_votes'].round(0).astype(int)\n# rename columns\naverage_votes.rename(columns={'score_bucket': 'IMDB Score', 'imdb_votes': 'Average Votes'}, inplace=True)\naverage_votes_sorted = average_votes.sort_values(by='IMDB Score', ascending=False)\n# print dataframe in descending order\naverage_votes_sorted"
  },
  {
   "cell_type": "markdown",
   "id": "af07386d",
   "metadata": {},
   "source": "The assumption macthes the analysis: the shows with the top 3 scores have the most amounts of votes."
  },
  {
   "cell_type": "markdown",
   "id": "84e29a37",
   "metadata": {},
   "source": "## Conclusion <a id='hypotheses'></a>"
  },
  {
   "cell_type": "markdown",
   "id": "984766a3",
   "metadata": {},
   "source": "The research done confirms that highly-rated shows released during the \"Golden Age\" of television also have the most votes. While shows with score 4 have more votes than ones with scores 5 and 6, the top three (scores 7-9) have the largest number. The data studied represents around 94% of the original set, so we can be confident in our findings."
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 339,
    "start_time": "2025-02-03T17:11:33.072Z"
   },
   {
    "duration": 5,
    "start_time": "2025-02-03T17:11:40.037Z"
   },
   {
    "duration": 180,
    "start_time": "2025-02-03T17:25:06.549Z"
   },
   {
    "duration": 12,
    "start_time": "2025-02-03T17:28:12.498Z"
   },
   {
    "duration": 13,
    "start_time": "2025-02-03T17:28:34.452Z"
   },
   {
    "duration": 16,
    "start_time": "2025-02-03T17:28:49.139Z"
   },
   {
    "duration": 11,
    "start_time": "2025-02-03T17:32:35.198Z"
   },
   {
    "duration": 12,
    "start_time": "2025-02-03T17:36:04.298Z"
   },
   {
    "duration": 12,
    "start_time": "2025-02-03T17:39:08.831Z"
   },
   {
    "duration": 13,
    "start_time": "2025-02-03T17:40:20.082Z"
   },
   {
    "duration": 12,
    "start_time": "2025-02-03T17:41:59.026Z"
   },
   {
    "duration": 158,
    "start_time": "2025-02-03T17:49:26.752Z"
   },
   {
    "duration": 11,
    "start_time": "2025-02-03T17:51:41.757Z"
   },
   {
    "duration": 5,
    "start_time": "2025-02-03T17:52:52.465Z"
   },
   {
    "duration": 7,
    "start_time": "2025-02-03T17:53:29.338Z"
   },
   {
    "duration": 5,
    "start_time": "2025-02-03T17:54:26.819Z"
   },
   {
    "duration": 12,
    "start_time": "2025-02-03T17:56:52.595Z"
   },
   {
    "duration": 348,
    "start_time": "2025-02-03T17:57:20.569Z"
   },
   {
    "duration": 461,
    "start_time": "2025-02-03T17:57:23.931Z"
   },
   {
    "duration": 12,
    "start_time": "2025-02-03T17:57:58.578Z"
   },
   {
    "duration": 60,
    "start_time": "2025-02-03T17:58:15.233Z"
   },
   {
    "duration": 12,
    "start_time": "2025-02-03T17:58:42.308Z"
   },
   {
    "duration": 163,
    "start_time": "2025-02-03T18:08:32.143Z"
   },
   {
    "duration": 272,
    "start_time": "2025-02-03T18:08:42.539Z"
   },
   {
    "duration": 373,
    "start_time": "2025-02-03T18:08:48.585Z"
   },
   {
    "duration": 141,
    "start_time": "2025-02-03T18:11:45.499Z"
   },
   {
    "duration": 18,
    "start_time": "2025-02-03T18:12:00.285Z"
   },
   {
    "duration": 24,
    "start_time": "2025-02-03T18:14:39.261Z"
   },
   {
    "duration": 4,
    "start_time": "2025-02-03T18:16:28.422Z"
   },
   {
    "duration": 9,
    "start_time": "2025-02-03T18:28:12.898Z"
   },
   {
    "duration": 18,
    "start_time": "2025-02-03T18:28:43.059Z"
   },
   {
    "duration": 6,
    "start_time": "2025-02-03T18:29:02.449Z"
   },
   {
    "duration": 22,
    "start_time": "2025-02-03T18:29:32.991Z"
   },
   {
    "duration": 3,
    "start_time": "2025-02-03T18:29:40.700Z"
   },
   {
    "duration": 8,
    "start_time": "2025-02-03T18:31:47.104Z"
   },
   {
    "duration": 10,
    "start_time": "2025-02-03T18:31:59.327Z"
   },
   {
    "duration": 6,
    "start_time": "2025-02-03T18:32:09.131Z"
   },
   {
    "duration": 17,
    "start_time": "2025-02-03T18:32:34.808Z"
   },
   {
    "duration": 9,
    "start_time": "2025-02-03T18:32:48.791Z"
   },
   {
    "duration": 4,
    "start_time": "2025-02-03T18:32:57.880Z"
   },
   {
    "duration": 20,
    "start_time": "2025-02-03T18:51:17.813Z"
   },
   {
    "duration": 37,
    "start_time": "2025-02-03T18:53:51.084Z"
   },
   {
    "duration": 33,
    "start_time": "2025-02-03T18:55:42.184Z"
   },
   {
    "duration": 212,
    "start_time": "2025-02-03T18:58:29.241Z"
   },
   {
    "duration": 19,
    "start_time": "2025-02-03T18:59:26.477Z"
   },
   {
    "duration": 4,
    "start_time": "2025-02-03T19:00:12.903Z"
   },
   {
    "duration": 32,
    "start_time": "2025-02-03T19:00:34.030Z"
   },
   {
    "duration": 27,
    "start_time": "2025-02-03T19:03:08.739Z"
   },
   {
    "duration": 18,
    "start_time": "2025-02-03T19:03:51.814Z"
   },
   {
    "duration": 29,
    "start_time": "2025-02-03T19:05:07.924Z"
   },
   {
    "duration": 18,
    "start_time": "2025-02-03T19:05:19.764Z"
   },
   {
    "duration": 15,
    "start_time": "2025-02-03T19:06:40.498Z"
   },
   {
    "duration": 38,
    "start_time": "2025-02-03T19:08:31.458Z"
   },
   {
    "duration": 33,
    "start_time": "2025-02-03T19:08:48.978Z"
   },
   {
    "duration": 38,
    "start_time": "2025-02-03T19:27:02.660Z"
   },
   {
    "duration": 8,
    "start_time": "2025-02-03T19:29:51.424Z"
   },
   {
    "duration": 9,
    "start_time": "2025-02-03T19:29:54.926Z"
   },
   {
    "duration": 10,
    "start_time": "2025-02-03T19:30:09.486Z"
   },
   {
    "duration": 7,
    "start_time": "2025-02-03T19:36:17.860Z"
   },
   {
    "duration": 9,
    "start_time": "2025-02-03T19:38:30.634Z"
   },
   {
    "duration": 14,
    "start_time": "2025-02-03T19:38:58.751Z"
   },
   {
    "duration": 3,
    "start_time": "2025-02-03T20:14:26.359Z"
   },
   {
    "duration": 17,
    "start_time": "2025-02-03T20:17:02.774Z"
   },
   {
    "duration": 4,
    "start_time": "2025-02-03T20:18:26.603Z"
   },
   {
    "duration": 16,
    "start_time": "2025-02-03T20:18:29.373Z"
   },
   {
    "duration": 222,
    "start_time": "2025-02-03T20:20:24.744Z"
   },
   {
    "duration": 10,
    "start_time": "2025-02-03T20:20:55.954Z"
   },
   {
    "duration": 37,
    "start_time": "2025-02-03T20:22:01.415Z"
   },
   {
    "duration": 16,
    "start_time": "2025-02-03T20:26:20.127Z"
   },
   {
    "duration": 9,
    "start_time": "2025-02-03T20:27:45.846Z"
   },
   {
    "duration": 157,
    "start_time": "2025-02-04T17:53:55.895Z"
   },
   {
    "duration": 12,
    "start_time": "2025-02-04T17:53:59.864Z"
   },
   {
    "duration": 2,
    "start_time": "2025-02-04T17:54:37.213Z"
   },
   {
    "duration": 11,
    "start_time": "2025-02-04T17:54:40.972Z"
   },
   {
    "duration": 297,
    "start_time": "2025-02-04T17:54:53.979Z"
   },
   {
    "duration": 137,
    "start_time": "2025-02-04T17:54:59.202Z"
   },
   {
    "duration": 13,
    "start_time": "2025-02-04T17:55:03.443Z"
   },
   {
    "duration": 23,
    "start_time": "2025-02-04T17:55:07.345Z"
   },
   {
    "duration": 4,
    "start_time": "2025-02-04T17:55:17.978Z"
   },
   {
    "duration": 36,
    "start_time": "2025-02-04T17:55:26.866Z"
   },
   {
    "duration": 8,
    "start_time": "2025-02-04T17:55:58.190Z"
   },
   {
    "duration": 4,
    "start_time": "2025-02-04T17:56:06.188Z"
   },
   {
    "duration": 18,
    "start_time": "2025-02-04T17:56:12.234Z"
   },
   {
    "duration": 39,
    "start_time": "2025-02-04T17:56:24.282Z"
   },
   {
    "duration": 18,
    "start_time": "2025-02-04T17:56:29.435Z"
   },
   {
    "duration": 39,
    "start_time": "2025-02-04T17:56:33.757Z"
   },
   {
    "duration": 45,
    "start_time": "2025-02-04T17:56:37.762Z"
   },
   {
    "duration": 8,
    "start_time": "2025-02-04T17:56:41.051Z"
   },
   {
    "duration": 13,
    "start_time": "2025-02-04T17:56:47.574Z"
   },
   {
    "duration": 9,
    "start_time": "2025-02-04T17:56:52.359Z"
   },
   {
    "duration": 3,
    "start_time": "2025-02-04T17:56:59.964Z"
   },
   {
    "duration": 15,
    "start_time": "2025-02-04T17:57:02.902Z"
   },
   {
    "duration": 13,
    "start_time": "2025-02-04T17:57:05.859Z"
   },
   {
    "duration": 10,
    "start_time": "2025-02-04T17:57:08.616Z"
   },
   {
    "duration": 373,
    "start_time": "2025-02-04T17:57:14.615Z"
   },
   {
    "duration": 20,
    "start_time": "2025-02-04T17:58:01.932Z"
   },
   {
    "duration": 13,
    "start_time": "2025-02-04T17:58:12.686Z"
   },
   {
    "duration": 18,
    "start_time": "2025-02-04T17:58:48.323Z"
   },
   {
    "duration": 13,
    "start_time": "2025-02-04T17:59:20.581Z"
   },
   {
    "duration": 37,
    "start_time": "2025-02-04T18:00:22.070Z"
   },
   {
    "duration": 13,
    "start_time": "2025-02-04T18:00:43.687Z"
   },
   {
    "duration": 12,
    "start_time": "2025-02-04T18:05:17.909Z"
   },
   {
    "duration": 20,
    "start_time": "2025-02-04T18:05:35.090Z"
   },
   {
    "duration": 15,
    "start_time": "2025-02-04T18:05:55.542Z"
   },
   {
    "duration": 14,
    "start_time": "2025-02-04T18:06:48.532Z"
   },
   {
    "duration": 15,
    "start_time": "2025-02-04T18:08:50.292Z"
   },
   {
    "duration": 7,
    "start_time": "2025-02-04T18:10:05.363Z"
   },
   {
    "duration": 7,
    "start_time": "2025-02-04T18:10:12.923Z"
   },
   {
    "duration": 162,
    "start_time": "2025-02-04T18:32:34.549Z"
   },
   {
    "duration": 313,
    "start_time": "2025-02-04T18:32:43.755Z"
   },
   {
    "duration": 123,
    "start_time": "2025-02-04T18:32:46.398Z"
   },
   {
    "duration": 14,
    "start_time": "2025-02-04T18:32:50.135Z"
   },
   {
    "duration": 24,
    "start_time": "2025-02-04T18:32:53.186Z"
   },
   {
    "duration": 4,
    "start_time": "2025-02-04T18:32:57.110Z"
   },
   {
    "duration": 8,
    "start_time": "2025-02-04T18:33:04.060Z"
   },
   {
    "duration": 3,
    "start_time": "2025-02-04T18:33:06.536Z"
   },
   {
    "duration": 19,
    "start_time": "2025-02-04T18:33:09.484Z"
   },
   {
    "duration": 36,
    "start_time": "2025-02-04T18:33:13.368Z"
   },
   {
    "duration": 19,
    "start_time": "2025-02-04T18:33:16.164Z"
   },
   {
    "duration": 42,
    "start_time": "2025-02-04T18:33:19.062Z"
   },
   {
    "duration": 43,
    "start_time": "2025-02-04T18:33:21.321Z"
   },
   {
    "duration": 9,
    "start_time": "2025-02-04T18:33:24.018Z"
   },
   {
    "duration": 13,
    "start_time": "2025-02-04T18:33:26.019Z"
   },
   {
    "duration": 9,
    "start_time": "2025-02-04T18:33:29.852Z"
   },
   {
    "duration": 2,
    "start_time": "2025-02-04T18:33:34.269Z"
   },
   {
    "duration": 15,
    "start_time": "2025-02-04T18:33:36.672Z"
   },
   {
    "duration": 6,
    "start_time": "2025-02-04T18:33:38.875Z"
   },
   {
    "duration": 18,
    "start_time": "2025-02-04T18:33:41.848Z"
   },
   {
    "duration": 15,
    "start_time": "2025-02-04T18:33:47.328Z"
   },
   {
    "duration": 6,
    "start_time": "2025-02-04T18:33:50.798Z"
   },
   {
    "duration": 7,
    "start_time": "2025-02-04T18:36:43.632Z"
   },
   {
    "duration": 10,
    "start_time": "2025-02-04T18:38:54.054Z"
   },
   {
    "duration": 7,
    "start_time": "2025-02-04T18:42:24.251Z"
   },
   {
    "duration": 336,
    "start_time": "2025-02-11T06:49:55.155Z"
   },
   {
    "duration": 140,
    "start_time": "2025-02-11T06:49:55.493Z"
   },
   {
    "duration": 18,
    "start_time": "2025-02-11T06:49:55.635Z"
   },
   {
    "duration": 23,
    "start_time": "2025-02-11T06:49:55.654Z"
   },
   {
    "duration": 3,
    "start_time": "2025-02-11T06:49:55.680Z"
   },
   {
    "duration": 5,
    "start_time": "2025-02-11T06:49:55.685Z"
   },
   {
    "duration": 6,
    "start_time": "2025-02-11T06:49:55.691Z"
   },
   {
    "duration": 46,
    "start_time": "2025-02-11T06:49:55.698Z"
   },
   {
    "duration": 33,
    "start_time": "2025-02-11T06:49:55.746Z"
   },
   {
    "duration": 18,
    "start_time": "2025-02-11T06:49:55.781Z"
   },
   {
    "duration": 60,
    "start_time": "2025-02-11T06:49:55.801Z"
   },
   {
    "duration": 44,
    "start_time": "2025-02-11T06:49:55.863Z"
   },
   {
    "duration": 60,
    "start_time": "2025-02-11T06:49:55.909Z"
   },
   {
    "duration": 12,
    "start_time": "2025-02-11T06:49:55.973Z"
   },
   {
    "duration": 9,
    "start_time": "2025-02-11T06:49:55.986Z"
   },
   {
    "duration": 2,
    "start_time": "2025-02-11T06:49:55.997Z"
   },
   {
    "duration": 14,
    "start_time": "2025-02-11T06:49:56.002Z"
   },
   {
    "duration": 26,
    "start_time": "2025-02-11T06:49:56.018Z"
   },
   {
    "duration": 19,
    "start_time": "2025-02-11T06:49:56.046Z"
   },
   {
    "duration": 16,
    "start_time": "2025-02-11T06:49:56.066Z"
   },
   {
    "duration": 15,
    "start_time": "2025-02-11T06:49:56.084Z"
   },
   {
    "duration": 6,
    "start_time": "2025-02-11T06:49:56.101Z"
   },
   {
    "duration": 37,
    "start_time": "2025-02-11T06:49:56.108Z"
   },
   {
    "duration": 10,
    "start_time": "2025-02-11T06:49:56.147Z"
   },
   {
    "duration": 6,
    "start_time": "2025-02-11T06:49:56.159Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
